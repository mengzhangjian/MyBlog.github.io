<!DOCTYPE html>
<html lang="en">

<head>
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-KB55E0GLN2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-KB55E0GLN2');
</script>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5557494619723966"
     crossorigin="anonymous"></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Every failure is leading towards success.">
    <meta name="keywords"  content="BY, BY Blog, 张建的博客, 张建, 计算机视觉, 机器人,Computer Vision">
    <meta name="theme-color" content="#000000">
    
    <title>解码的生成多样性 - 张建的博客 | BY Blog</title>

    <!-- Web App Manifest -->
    <link rel="manifest" href="/pwa/manifest.json">

    <!-- Favicon -->
    <link rel="shortcut icon" href="/img/favicon.ico">

    <!-- Safari Webpage Icon    by-BY -->
    <link rel="apple-touch-icon" href="/img/apple-touch-icon.png">
    
    <!-- Canonical URL -->
    <link rel="canonical" href="http://0.0.0.0:4000/2023/08/14/%E8%A7%A3%E7%A0%81%E7%9A%84%E7%94%9F%E6%88%90%E5%A4%9A%E6%A0%B7%E6%80%A7/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/hux-blog.min.css">

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Custom Fonts -->
    <!-- <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5557494619723966"
     crossorigin="anonymous"></script>

    <!-- Hux Delete, sad but pending in China
    <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/
    css'>
    -->


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Alpha</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>
                    
                    <li>
                        <a href="/about/">About</a>
                    </li>
                    
                    <li>
                        <a href="/tags/">Tags</a>
                    </li>
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    var __HuxNav__ = {
        close: function(){
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        },
        open: function(){
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }

    // Bind Event
    $toggle.addEventListener('click', function(e){
        if ($navbar.className.indexOf('in') > 0) {
            __HuxNav__.close()
        }else{
            __HuxNav__.open()
        }
    })

    /**
     * Since Fastclick is used to delegate 'touchstart' globally
     * to hack 300ms delay in iOS by performing a fake 'click',
     * Using 'e.stopPropagation' to stop 'touchstart' event from 
     * $toggle/$collapse will break global delegation.
     * 
     * Instead, we use a 'e.target' filter to prevent handler
     * added to document close HuxNav.  
     *
     * Also, we use 'click' instead of 'touchstart' as compromise
     */
    document.addEventListener('click', function(e){
        if(e.target == $toggle) return;
        if(e.target.className == 'icon-bar') return;
        __HuxNav__.close();
    })
</script>


    <!-- Image to hack wechat -->
<!-- <img src="/img/icon_wechat.png" width="0" height="0"> -->
<!-- <img src="/img/post-bg-mma-4.jpg" width="0" height="0"> -->

<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        position: relative;
        background-image: url('/img/post-bg-mma-4.jpg')
    }

    
</style>
<header class="intro-header" >
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-KB55E0GLN2"></script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-KB55E0GLN2');
</script>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5557494619723966"
     crossorigin="anonymous"></script>
    <div class="header-mask"></div>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/tags/#大模型" title="大模型">大模型</a>
                        
                    </div>
                    <h1>解码的生成多样性</h1>
                    
                    
                    <h2 class="subheading">是大模型呀</h2>
                    
                    <span class="meta">Posted by BY    J on August 14, 2023</span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

    <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

				<h1 id="解码的生成多样性">解码的生成多样性</h1>

<p>原文出处:</p>

<ul>
  <li><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/text_generation">https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/text_generation</a></li>
  <li><a href="https://huggingface.co/blog/zh/how-to-generate">https://huggingface.co/blog/zh/how-to-generate</a></li>
</ul>

<p>对于自回归文本生成任务中的预训练模型，每一个框架都有对应的generate生成方法，一般封装在各自的GnenerationMixin class中。</p>

<p>这个类对外提供generate()方法，可以用于:</p>

<ul>
  <li>greedy decoding: 当num_beams=1且do_sample=False，调用greedy_search()方法</li>
  <li>multinomial: 当num_beams=1且do_sample=True，调用sample()方法</li>
  <li>beam-search: 当num_beams &gt; 1且do_sample=False， 调用beam_search()方法</li>
  <li>beam-search multinomial: 当 num_beams &gt; 1且do_sample=True，调用beam_sample()方法</li>
  <li>diverse beam-search: 当num_beams &gt; 1且num_beam_groups &gt; 1 调用 group_beam_search()方法</li>
  <li>constrained beam-search: 当constraints ≠ None或force_words_ids ≠ None, 调用constrained_beam_search()方法</li>
</ul>

<p>笔者在实际操作过程中，发现一些参数对实际生成效果会有不少的影响，所以在讲解具体的参数之前，先回顾下主要的解码算法原理。</p>

<h3 id="自回归语言生成任务">自回归语言生成任务</h3>

<p>自回归语言生成任务基于如下假设: 一个文本序列的概率分布可以分解为每个词基于其上文的条件概率的乘积。</p>

<script type="math/tex; mode=display">P(w_{1:T}|w_0) = \prod_{t=1} ^T P(w_t|w_{1:t-1}, W_0), 其中w_{1:0} = \emptyset</script>

<p>上式中，<script type="math/tex">w_0</script> 是初始上下文单词序列。文本序列的长度 <script type="math/tex">T</script> 通常是变的，并且对应于时间步 <script type="math/tex">t = T</script>。<script type="math/tex">P(w_{t} w_{1:t-1}, w_0)</script>的词表中已包含终止符(EOS)。</p>

<h3 id="greedy-search贪心搜索">Greedy Search(贪心搜索)</h3>

<p>贪心搜索在每个时间步<script type="math/tex">t</script>都简单的选择概率最高的词作为当前输出词: <script type="math/tex">w_t = argmax_{w} P(w_{t}|w_{1:t-1})</script>，如下图所示</p>

<p><img src="https://res.cloudinary.com/dsn0i1fsm/image/upload/v1692014779/blog/decoder/Untitled_tyombp.png" alt="Untitled" /></p>

<p>从单词<script type="math/tex">\text{The}</script>开始，算法在第一步贪心的选择条件概率最高的词<script type="math/tex">\text{nice}</script>作为输出，依次往后。最终生成的单词序列为<script type="math/tex">\text{The}, \text{nice}, \text{woman}</script>，其联合概率为<script type="math/tex">0.5 \times 0.4 = 0.2</script>。</p>

<p>下面，我们输入文本序列<script type="math/tex">\text{I} \space \text{enjoy}\space \text{walking}\space\text{with}\space\text{my}\space\text{cute}\space\text{dog}</script>给GPT2模型，让模型生成下文。我们以此为例看如何在transformers中使用贪心搜索:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># encode context the generation is conditioned on
</span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'I enjoy walking with my cute dog'</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s">'tf'</span><span class="p">)</span>

<span class="c1"># generate text until the output length (which includes the context length) reaches 50
</span><span class="n">greedy_output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Output:</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="mi">100</span> <span class="o">*</span> <span class="s">'-'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">greedy_output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Output</span><span class="p">:</span>
<span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="n">I</span> <span class="n">enjoy</span> <span class="n">walking</span> <span class="k">with</span> <span class="n">my</span> <span class="n">cute</span> <span class="n">dog</span><span class="p">,</span> <span class="n">but</span> <span class="n">I</span><span class="s">'m not sure if I'</span><span class="n">ll</span> <span class="n">ever</span> <span class="n">be</span> <span class="n">able</span> <span class="n">to</span> <span class="n">walk</span> <span class="k">with</span> <span class="n">my</span> <span class="n">dog</span><span class="o">.</span> <span class="n">I</span><span class="s">'m not sure if I'</span><span class="n">ll</span> <span class="n">ever</span> <span class="n">be</span> <span class="n">able</span> <span class="n">to</span> <span class="n">walk</span> <span class="k">with</span> <span class="n">my</span> <span class="n">dog</span><span class="o">.</span>

<span class="n">I</span><span class="s">'m not sure if I'</span><span class="n">ll</span>
</code></pre></div></div>

<p>根据上文生成的单词是合理的，但<strong>模型很快开始输出重复文本</strong>！这在语言生成中是一个非常普遍的问题，在贪心搜索和波束搜索中更是如此-详见论文<a href="https://arxiv.org/abs/1610.02424">1</a>与论文<a href="https://arxiv.org/abs/1701.03185">2</a>。</p>

<p>贪心搜索的主要缺点是它错过了隐藏在低概率词后面的高概率词，如上图所示:</p>

<p>条件概率为<script type="math/tex">0.9</script>的单词<script type="math/tex">\text{has}</script>隐藏在单词<script type="math/tex">\text{dog}</script>的后面，而<script type="math/tex">\text{dog}</script>因为在<script type="math/tex">t=1</script>时条件概率值只排第二所以未被选择，因此贪心搜索会错过序列<script type="math/tex">\text{The}\space\text{dog}\space\text{has}</script>。</p>

<p>幸好可以用波束搜索来缓解这个问题!</p>

<h3 id="波束搜索">波束搜索</h3>

<p>波束搜索通过在每个时间步保留最可能的nums_beams个词，并从中最终选择出概率最高的序列来降低丢失潜在的高概率序列的风险。以num_beams=2为例:</p>

<p><img src="https://res.cloudinary.com/dsn0i1fsm/image/upload/v1692014779/blog/decoder/Untitled_1_ibjkje.png" alt="Untitled" /></p>

<p>在时间步1，除了最有可能的假设<script type="math/tex">\text{The}\space\text{nice}</script>，波束搜索还跟踪第二可能的假设<script type="math/tex">\text{The}\space\text{dog}。</script>在时间步2，波束搜索发现序列<script type="math/tex">\text{The}\space\text{dog}\space\text{has}</script>概率为<script type="math/tex">0.36</script>，比<script type="math/tex">\text{The}\space\text{nice}\space\text{woman}</script>的<script type="math/tex">0.2</script>更高。在此例中，它已经找到了最有可能的序列。</p>

<p>波束搜索一般都会找到比贪心搜索概率更高的输出序列，但仍不保证找到全局最优解。</p>

<p>我们设置num_beams &gt; 1和early_stopping = True以便在所有波束达到EOS时直接结束生成。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># activate beam search and early_stopping
</span><span class="n">beam_output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">input_ids</span><span class="p">,</span> 
    <span class="n">max_length</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
    <span class="n">num_beams</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
    <span class="n">early_stopping</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Output:</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="mi">100</span> <span class="o">*</span> <span class="s">'-'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">beam_output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Output</span><span class="p">:</span>
<span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="n">I</span> <span class="n">enjoy</span> <span class="n">walking</span> <span class="k">with</span> <span class="n">my</span> <span class="n">cute</span> <span class="n">dog</span><span class="p">,</span> <span class="n">but</span> <span class="n">I</span><span class="s">'m not sure if I'</span><span class="n">ll</span> <span class="n">ever</span> <span class="n">be</span> <span class="n">able</span> <span class="n">to</span> <span class="n">walk</span> <span class="k">with</span> <span class="n">him</span> <span class="n">again</span><span class="o">.</span>

<span class="n">I</span><span class="s">'m not sure if I'</span><span class="n">ll</span> <span class="n">ever</span> <span class="n">be</span> <span class="n">able</span> <span class="n">to</span> <span class="n">walk</span> <span class="k">with</span> <span class="n">him</span> <span class="n">again</span><span class="o">.</span> <span class="n">I</span><span class="s">'m not sure if I'</span><span class="n">ll</span>
</code></pre></div></div>

<p>虽然结果比贪心搜索更流畅，但输出中仍然包含重复。一个简单的补救措施是引入<script type="math/tex">n-grams</script>（即连续n个词的词序列）惩罚，该方法是由<a href="https://arxiv.org/abs/1705.04304">Paulus(2017)</a>和<a href="https://arxiv.org/abs/1705.04304">Klein(2017)</a>引入的。最常见的n-grams惩罚是确保每个n-gram都只出现一次，方法是如果看到当前候选词与其上文所组成的n-gram已经出现过了，就将该候选词的概率设置为0。</p>

<p>我们可以通过设置no_repeat_ngram_size = 2来试试，这样任意2-gram不会出现两次:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># set no_repeat_ngram_size to 2
</span><span class="n">beam_output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">input_ids</span><span class="p">,</span> 
    <span class="n">max_length</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
    <span class="n">num_beams</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
    <span class="n">no_repeat_ngram_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
    <span class="n">early_stopping</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Output:</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="mi">100</span> <span class="o">*</span> <span class="s">'-'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">beam_output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Output</span><span class="p">:</span>
<span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="n">I</span> <span class="n">enjoy</span> <span class="n">walking</span> <span class="k">with</span> <span class="n">my</span> <span class="n">cute</span> <span class="n">dog</span><span class="p">,</span> <span class="n">but</span> <span class="n">I</span><span class="s">'m not sure if I'</span><span class="n">ll</span> <span class="n">ever</span> <span class="n">be</span> <span class="n">able</span> <span class="n">to</span> <span class="n">walk</span> <span class="k">with</span> <span class="n">him</span> <span class="n">again</span><span class="o">.</span>

<span class="n">I</span><span class="s">'ve been thinking about this for a while now, and I think it'</span><span class="n">s</span> <span class="n">time</span> <span class="k">for</span> <span class="n">me</span> <span class="n">to</span> <span class="n">take</span> <span class="n">a</span> <span class="k">break</span>
</code></pre></div></div>

<p>我们看到生成的文本已经没有重复了。但是，n-gram惩罚使用时必须谨慎，例如包含地名的文章里就不应该使用2-gram惩罚，否则，城市名称在整个文本中将只出现一次。</p>

<p>在transformers中，我们只需要将参数num_return_sequences设置为需返回的概率最高的波束的数量，记得确保num_return_sequences ≤ num_beams !</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># set return_num_sequences &gt; 1
</span><span class="n">beam_outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">input_ids</span><span class="p">,</span> 
    <span class="n">max_length</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
    <span class="n">num_beams</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
    <span class="n">no_repeat_ngram_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
    <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
    <span class="n">early_stopping</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>

<span class="c1"># now we have 3 output sequences
</span><span class="k">print</span><span class="p">(</span><span class="s">"Output:</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="mi">100</span> <span class="o">*</span> <span class="s">'-'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">beam_output</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">beam_outputs</span><span class="p">):</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"{}: {}"</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">beam_output</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Output</span><span class="p">:</span>
<span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="mi">0</span><span class="p">:</span> <span class="n">I</span> <span class="n">enjoy</span> <span class="n">walking</span> <span class="k">with</span> <span class="n">my</span> <span class="n">cute</span> <span class="n">dog</span><span class="p">,</span> <span class="n">but</span> <span class="n">I</span><span class="s">'m not sure if I'</span><span class="n">ll</span> <span class="n">ever</span> <span class="n">be</span> <span class="n">able</span> <span class="n">to</span> <span class="n">walk</span> <span class="k">with</span> <span class="n">him</span> <span class="n">again</span><span class="o">.</span>

<span class="n">I</span><span class="s">'ve been thinking about this for a while now, and I think it'</span><span class="n">s</span> <span class="n">time</span> <span class="k">for</span> <span class="n">me</span> <span class="n">to</span> <span class="n">take</span> <span class="n">a</span> <span class="k">break</span>
<span class="mi">1</span><span class="p">:</span> <span class="n">I</span> <span class="n">enjoy</span> <span class="n">walking</span> <span class="k">with</span> <span class="n">my</span> <span class="n">cute</span> <span class="n">dog</span><span class="p">,</span> <span class="n">but</span> <span class="n">I</span><span class="s">'m not sure if I'</span><span class="n">ll</span> <span class="n">ever</span> <span class="n">be</span> <span class="n">able</span> <span class="n">to</span> <span class="n">walk</span> <span class="k">with</span> <span class="n">him</span> <span class="n">again</span><span class="o">.</span>

<span class="n">I</span><span class="s">'ve been thinking about this for a while now, and I think it'</span><span class="n">s</span> <span class="n">time</span> <span class="k">for</span> <span class="n">me</span> <span class="n">to</span> <span class="n">get</span> <span class="n">back</span> <span class="n">to</span>
<span class="mi">2</span><span class="p">:</span> <span class="n">I</span> <span class="n">enjoy</span> <span class="n">walking</span> <span class="k">with</span> <span class="n">my</span> <span class="n">cute</span> <span class="n">dog</span><span class="p">,</span> <span class="n">but</span> <span class="n">I</span><span class="s">'m not sure if I'</span><span class="n">ll</span> <span class="n">ever</span> <span class="n">be</span> <span class="n">able</span> <span class="n">to</span> <span class="n">walk</span> <span class="k">with</span> <span class="n">her</span> <span class="n">again</span><span class="o">.</span>

<span class="n">I</span><span class="s">'ve been thinking about this for a while now, and I think it'</span><span class="n">s</span> <span class="n">time</span> <span class="k">for</span> <span class="n">me</span> <span class="n">to</span> <span class="n">take</span> <span class="n">a</span> <span class="k">break</span>
<span class="mi">3</span><span class="p">:</span> <span class="n">I</span> <span class="n">enjoy</span> <span class="n">walking</span> <span class="k">with</span> <span class="n">my</span> <span class="n">cute</span> <span class="n">dog</span><span class="p">,</span> <span class="n">but</span> <span class="n">I</span><span class="s">'m not sure if I'</span><span class="n">ll</span> <span class="n">ever</span> <span class="n">be</span> <span class="n">able</span> <span class="n">to</span> <span class="n">walk</span> <span class="k">with</span> <span class="n">her</span> <span class="n">again</span><span class="o">.</span>

<span class="n">I</span><span class="s">'ve been thinking about this for a while now, and I think it'</span><span class="n">s</span> <span class="n">time</span> <span class="k">for</span> <span class="n">me</span> <span class="n">to</span> <span class="n">get</span> <span class="n">back</span> <span class="n">to</span>
<span class="mi">4</span><span class="p">:</span> <span class="n">I</span> <span class="n">enjoy</span> <span class="n">walking</span> <span class="k">with</span> <span class="n">my</span> <span class="n">cute</span> <span class="n">dog</span><span class="p">,</span> <span class="n">but</span> <span class="n">I</span><span class="s">'m not sure if I'</span><span class="n">ll</span> <span class="n">ever</span> <span class="n">be</span> <span class="n">able</span> <span class="n">to</span> <span class="n">walk</span> <span class="k">with</span> <span class="n">him</span> <span class="n">again</span><span class="o">.</span>

<span class="n">I</span><span class="s">'ve been thinking about this for a while now, and I think it'</span><span class="n">s</span> <span class="n">time</span> <span class="k">for</span> <span class="n">me</span> <span class="n">to</span> <span class="n">take</span> <span class="n">a</span> <span class="n">step</span>
</code></pre></div></div>

<p>可见，五个波束彼此之间仅有少量差别 ———这在仅使用5个波束时不足为奇。</p>

<p>开放域文本生成的研究人员最近提出了几个理由来说明对该领域而言波束搜索可能不是最佳方案:</p>

<ul>
  <li>在机器翻译或摘要等任务中，因为所需生成的长度或多或少都是可预测的，所以波束搜索效果比较好——参见<a href="https://arxiv.org/abs/1808.10006">Murray(2018)</a>和<a href="https://arxiv.org/abs/1808.09582">Yang(2018)</a>的工作。但开放域文本生成情况有所不同，其输出文本长度可能会有很大差异，如对话和故事生成的输出文本长度就有很大不同。</li>
  <li>我们已经看到波束搜索已被证明存在重复生成的问题。在故事生成这样的场景中，很难用n-gram或其他惩罚来控制，因为在”不重复”和最大可重复n-grams之间找到一个好的折衷需要大量的微调</li>
  <li>正如<a href="https://arxiv.org/abs/1904.09751">Ari Holtzman(2019)</a>所论证的那样，高质量的人类语言并不遵循最大概率法则。换句话说，作为人类，我们希望生成的文本能让我们感到惊喜，而可预测的文本使人感到无聊。论文作者画了一个概率图，很好的展示了这一点，从图中可以看出人类文本带来的惊喜度比波束搜索好不少。</li>
</ul>

<p><img src="https://res.cloudinary.com/dsn0i1fsm/image/upload/v1692014779/blog/decoder/Untitled_2_dcizxw.png" alt="Untitled" /></p>

<p>因此，让我们开始玩点刺激的，引入一些随机性🤪。</p>

<h3 id="采样">采样</h3>

<p>在其最基本的形式中，采样意味着根据当前条件概率分布随机选择输出词<script type="math/tex">w_t</script>。</p>

<script type="math/tex; mode=display">w_t \sim P(w|w_{1:t-1})</script>

<p>继续使用上文中的例子，下图可视化了使用采样生成文本的过程。</p>

<p><img src="https://res.cloudinary.com/dsn0i1fsm/image/upload/v1692014779/blog/decoder/Untitled_3_ylutyz.png" alt="Untitled" /></p>

<p>很明显，使用采样方法时文本生成本身不再是确定性的。单词<script type="math/tex">\text{car}</script>从条件概率分布<script type="math/tex"></script>P(w\text{The})</script>中采样而得，而<script type="math/tex">\text{drivers}</script>则采样自<script type="math/tex">P(w\text{The}\space\text{car})。</script></p>

<p>在transformers中，我们设置do_sample=True并通过设置top_k=0停用Top-K采样(稍后详细介绍)。在下文中，为便于复现，我们会固定random_seed=0，但你可以在自己的模型中随意更改random_seed。</p>

<div class="language-jsx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">#</span> <span class="kd">set</span> <span class="nx">seed</span> <span class="nx">to</span> <span class="nx">reproduce</span> <span class="nx">results</span><span class="p">.</span> <span class="nx">Feel</span> <span class="nx">free</span> <span class="nx">to</span> <span class="nx">change</span> <span class="nx">the</span> <span class="nx">seed</span> <span class="nx">though</span> <span class="nx">to</span> <span class="kd">get</span> <span class="nx">different</span> <span class="nx">results</span>
<span class="nx">tf</span><span class="p">.</span><span class="nx">random</span><span class="p">.</span><span class="nx">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="err">#</span> <span class="nx">activate</span> <span class="nx">sampling</span> <span class="nx">and</span> <span class="nx">deactivate</span> <span class="nx">top_k</span> <span class="nx">by</span> <span class="nx">setting</span> <span class="nx">top_k</span> <span class="nx">sampling</span> <span class="nx">to</span> <span class="mi">0</span>
<span class="nx">sample_output</span> <span class="o">=</span> <span class="nx">model</span><span class="p">.</span><span class="nx">generate</span><span class="p">(</span>
    <span class="nx">input_ids</span><span class="p">,</span> 
    <span class="nx">do_sample</span><span class="o">=</span><span class="nx">True</span><span class="p">,</span> 
    <span class="nx">max_length</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
    <span class="nx">top_k</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>

<span class="nx">print</span><span class="p">(</span><span class="dl">"</span><span class="s2">Output:</span><span class="se">\n</span><span class="dl">"</span> <span class="o">+</span> <span class="mi">100</span> <span class="o">*</span> <span class="dl">'</span><span class="s1">-</span><span class="dl">'</span><span class="p">)</span>
<span class="nx">print</span><span class="p">(</span><span class="nx">tokenizer</span><span class="p">.</span><span class="nx">decode</span><span class="p">(</span><span class="nx">sample_output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nx">skip_special_tokens</span><span class="o">=</span><span class="nx">True</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-jsx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">Output</span><span class="p">:</span>
<span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="nx">I</span> <span class="nx">enjoy</span> <span class="nx">walking</span> <span class="kd">with</span> <span class="nx">my</span> <span class="nx">cute</span> <span class="nx">dog</span><span class="p">.</span> <span class="nx">He</span> <span class="nx">just</span> <span class="nx">gave</span> <span class="nx">me</span> <span class="nx">a</span> <span class="nx">whole</span> <span class="k">new</span> <span class="nx">hand</span> <span class="nx">sense</span><span class="p">.</span><span class="dl">"</span><span class="s2">

But it seems that the dogs have learned a lot from teasing at the local batte harness once they take on the outside.

</span><span class="dl">"</span><span class="nx">I</span> <span class="nx">take</span>
</code></pre></div></div>

<p>生成的文本看起来不错～但仔细观察会发现它不是很连贯。3-grams new hand scene和local batte harness 非常奇怪，看起来不像是人写的。这就是对单词序列进行采样时的大问题：模型通常会产生不连贯的乱码，参见<a href="https://arxiv.org/abs/1904.09751">Ari Holtzman(2019)</a>的论文。</p>

<p>缓解这一问题的一个技巧是通过降低所谓的softmax的温度使分布<script type="math/tex"> P(w|w_{1:t-1}) </script>更陡峭。而降低“温度”，本质上是增加高概率单词的似然并降低低概率单词的似然。</p>


<p>将温度应用到于我们的例子中后，结果如下图所示:</p>

<p><img src="https://res.cloudinary.com/dsn0i1fsm/image/upload/v1692014779/blog/decoder/Untitled_4_k7lqeq.png" alt="Untitled" /></p>

<p><script type="math/tex">t=1</script>的时刻单词的条件分布变得更加陡峭，几乎没有机会选择单词<script type="math/tex">\text{car}</script>了。</p>

<p>让我们看看如何通过设置temperature=0.7来冷却生成过程：</p>

<div class="language-jsx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">#</span> <span class="kd">set</span> <span class="nx">seed</span> <span class="nx">to</span> <span class="nx">reproduce</span> <span class="nx">results</span><span class="p">.</span> <span class="nx">Feel</span> <span class="nx">free</span> <span class="nx">to</span> <span class="nx">change</span> <span class="nx">the</span> <span class="nx">seed</span> <span class="nx">though</span> <span class="nx">to</span> <span class="kd">get</span> <span class="nx">different</span> <span class="nx">results</span>
<span class="nx">tf</span><span class="p">.</span><span class="nx">random</span><span class="p">.</span><span class="nx">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="err">#</span> <span class="nx">use</span> <span class="nx">temperature</span> <span class="nx">to</span> <span class="nx">decrease</span> <span class="nx">the</span> <span class="nx">sensitivity</span> <span class="nx">to</span> <span class="nx">low</span> <span class="nx">probability</span> <span class="nx">candidates</span>
<span class="nx">sample_output</span> <span class="o">=</span> <span class="nx">model</span><span class="p">.</span><span class="nx">generate</span><span class="p">(</span>
    <span class="nx">input_ids</span><span class="p">,</span> 
    <span class="nx">do_sample</span><span class="o">=</span><span class="nx">True</span><span class="p">,</span> 
    <span class="nx">max_length</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
    <span class="nx">top_k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
    <span class="nx">temperature</span><span class="o">=</span><span class="mf">0.7</span>
<span class="p">)</span>

<span class="nx">print</span><span class="p">(</span><span class="dl">"</span><span class="s2">Output:</span><span class="se">\n</span><span class="dl">"</span> <span class="o">+</span> <span class="mi">100</span> <span class="o">*</span> <span class="dl">'</span><span class="s1">-</span><span class="dl">'</span><span class="p">)</span>
<span class="nx">print</span><span class="p">(</span><span class="nx">tokenizer</span><span class="p">.</span><span class="nx">decode</span><span class="p">(</span><span class="nx">sample_output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nx">skip_special_tokens</span><span class="o">=</span><span class="nx">True</span><span class="p">))</span>
</code></pre></div></div>

<p>可以看到，奇怪的n-gram变少了，现在输出更连贯了。虽然温度可以使分布的随机性降低，但极限条件下，当“温度”设置为0时，温度缩放采样就退化成贪心解码了，因此会遇到与贪心解码相同的问题。</p>

<h3 id="top-k采样">Top-K采样</h3>

<p><a href="https://arxiv.org/pdf/1805.04833.pdf">Fan(2018)</a>等人的论文介绍了一种简单但非常强大的采样方案，成为<strong>Top-K</strong>采样。在<strong>Top-K</strong>采样中，概率最大的K个单词会被选出，然后这K个词的概率会被重新归一化，最后就在这重新被归一化概率后的K个词中采样。GPT2采用了这种方案，这也是它在故事生成这样的任务上取得成功的原因之一。</p>

<p>我们将上文例子中的候选单词数从3个单词扩展到10个单词，以更好的说明<strong>Top-K</strong>采样。</p>

<p><img src="https://res.cloudinary.com/dsn0i1fsm/image/upload/v1692014779/blog/decoder/Untitled_5_zsjzsm.png" alt="Untitled" /></p>

<p>设<script type="math/tex">k = 6</script>，即我们将在两个采样步的采样池大小限制为6个单词。我们定义6个最有可能的词的集合为<script type="math/tex">V_{\text{top-K}}</script>。在第一步中，<script type="math/tex">V_{\text{top-K}}</script>仅占概率的大约三分之二，但在第二步，它几乎占了全部的概率。同时，我们可以看到在第二步该方法成功的消除了那些奇怪的候选词<script type="math/tex">\text{not}，\text{small}，\text{told}</script>。</p>

<p>我们设置top_k=50为例看下如何在transformers库中使用<strong>Top-K</strong>：</p>

<div class="language-jsx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">#</span> <span class="kd">set</span> <span class="nx">seed</span> <span class="nx">to</span> <span class="nx">reproduce</span> <span class="nx">results</span><span class="p">.</span> <span class="nx">Feel</span> <span class="nx">free</span> <span class="nx">to</span> <span class="nx">change</span> <span class="nx">the</span> <span class="nx">seed</span> <span class="nx">though</span> <span class="nx">to</span> <span class="kd">get</span> <span class="nx">different</span> <span class="nx">results</span>
<span class="nx">tf</span><span class="p">.</span><span class="nx">random</span><span class="p">.</span><span class="nx">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="err">#</span> <span class="kd">set</span> <span class="nx">top_k</span> <span class="nx">to</span> <span class="mi">50</span>
<span class="nx">sample_output</span> <span class="o">=</span> <span class="nx">model</span><span class="p">.</span><span class="nx">generate</span><span class="p">(</span>
    <span class="nx">input_ids</span><span class="p">,</span> 
    <span class="nx">do_sample</span><span class="o">=</span><span class="nx">True</span><span class="p">,</span> 
    <span class="nx">max_length</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
    <span class="nx">top_k</span><span class="o">=</span><span class="mi">50</span>
<span class="p">)</span>

<span class="nx">print</span><span class="p">(</span><span class="dl">"</span><span class="s2">Output:</span><span class="se">\n</span><span class="dl">"</span> <span class="o">+</span> <span class="mi">100</span> <span class="o">*</span> <span class="dl">'</span><span class="s1">-</span><span class="dl">'</span><span class="p">)</span>
<span class="nx">print</span><span class="p">(</span><span class="nx">tokenizer</span><span class="p">.</span><span class="nx">decode</span><span class="p">(</span><span class="nx">sample_output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nx">skip_special_tokens</span><span class="o">=</span><span class="nx">True</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-jsx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">Output</span><span class="p">:</span>
<span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="nx">I</span> <span class="nx">enjoy</span> <span class="nx">walking</span> <span class="kd">with</span> <span class="nx">my</span> <span class="nx">cute</span> <span class="nx">dog</span><span class="p">.</span> <span class="nx">It</span><span class="dl">'</span><span class="s1">s so good to have an environment where your dog is available to share with you and we</span><span class="dl">'</span><span class="nx">ll</span> <span class="nx">be</span> <span class="nx">taking</span> <span class="nx">care</span> <span class="k">of</span> <span class="nx">you</span><span class="p">.</span>

<span class="nx">We</span> <span class="nx">hope</span> <span class="nx">you</span><span class="dl">'</span><span class="s1">ll find this story interesting!

I am from
</span></code></pre></div></div>


相当不错。该文本可以说是迄今为止生成的最“像人”的文本。现在还有一个问题，Top-K采样不会动态调整从需要概率分布<script type="math/tex">P(w|w_{1:t-1})</script>中选出的单词。这可能会有问题，因为某些分布可能是非常尖锐（上图中右侧的分布），而另一些可能更平坦（上图中左侧的分布），所以对不同的分布使用同一个绝对数<script type="math/tex">K</script>可能并不普适。


<p>在<script type="math/tex">t=1</script>时，Top-K将<script type="math/tex">\text{people}，\text{big}，\text{house}，\text{cat}</script>排出了采样池，而这些词似乎是合理的候选词。另一方面，在<script type="math/tex">t=2</script>时，该方法却又把不太合适的<script type="math/tex">\text{down}，\text{a}</script>纳入了采样池。因此，将采样池限制为固定大小K可能会在分布比较尖锐的时候产生胡言乱语，而在分布比较平坦的时候限制模型的创造力。这一发现促使<a href="https://arxiv.org/abs/1904.09751">Ari Holtzman（2019）</a>发明了<strong>Top-P或核-采样。</strong></p>

<h3 id="top-p核采样">Top-p（核）采样</h3>

<p>在Top-p中，采样不只是在最有可能的K个单词中进行，而是在累积概率超过概率p的最小单词集中进行。然后在这组词中重新分配概率质量。这样，词集的大小（又名集合中的词数）可以根据下一个词的概率分布动态增加和减少。</p>

<p><img src="https://res.cloudinary.com/dsn0i1fsm/image/upload/v1692014779/blog/decoder/Untitled_6_ohntkd.png" alt="Untitled" /></p>

<p>假设<script type="math/tex">p=0.92</script>，Top-p采样对单词概率进行降序排列并累加，然后选择概率和首次超过<script type="math/tex">p=92%</script>%的单词集作为采样池，定义为<script type="math/tex">V_{\text{top-p}}</script>。在<script type="math/tex">t=1</script>时<script type="math/tex">V_{\text{top-p}}</script>有9个词，而在<script type="math/tex">t=2</script>时它只需要选择前3个词就超过了<script type="math/tex">92%</script>%。其实很简单吧！可以看出，在单词比较不可预测时，它保留了更多的候选词，如<script type="math/tex">P(w\text{The})</script>，而当单词似乎更容易预测时，只保留了几个候选词，如<script type="math/tex">P(w\text{The}，\text{car})</script>。

<p>我们可以通过设置0 &lt; top_p &lt; 1来激活Top-p采样：</p>

<div class="language-jsx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">#</span> <span class="kd">set</span> <span class="nx">seed</span> <span class="nx">to</span> <span class="nx">reproduce</span> <span class="nx">results</span><span class="p">.</span> <span class="nx">Feel</span> <span class="nx">free</span> <span class="nx">to</span> <span class="nx">change</span> <span class="nx">the</span> <span class="nx">seed</span> <span class="nx">though</span> <span class="nx">to</span> <span class="kd">get</span> <span class="nx">different</span> <span class="nx">results</span>
<span class="nx">tf</span><span class="p">.</span><span class="nx">random</span><span class="p">.</span><span class="nx">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="err">#</span> <span class="nx">deactivate</span> <span class="nx">top_k</span> <span class="nx">sampling</span> <span class="nx">and</span> <span class="nx">sample</span> <span class="nx">only</span> <span class="k">from</span> <span class="mi">92</span><span class="o">%</span> <span class="nx">most</span> <span class="nx">likely</span> <span class="nx">words</span>
<span class="nx">sample_output</span> <span class="o">=</span> <span class="nx">model</span><span class="p">.</span><span class="nx">generate</span><span class="p">(</span>
    <span class="nx">input_ids</span><span class="p">,</span> 
    <span class="nx">do_sample</span><span class="o">=</span><span class="nx">True</span><span class="p">,</span> 
    <span class="nx">max_length</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
    <span class="nx">top_p</span><span class="o">=</span><span class="mf">0.92</span><span class="p">,</span> 
    <span class="nx">top_k</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>

<span class="nx">print</span><span class="p">(</span><span class="dl">"</span><span class="s2">Output:</span><span class="se">\n</span><span class="dl">"</span> <span class="o">+</span> <span class="mi">100</span> <span class="o">*</span> <span class="dl">'</span><span class="s1">-</span><span class="dl">'</span><span class="p">)</span>
<span class="nx">print</span><span class="p">(</span><span class="nx">tokenizer</span><span class="p">.</span><span class="nx">decode</span><span class="p">(</span><span class="nx">sample_output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nx">skip_special_tokens</span><span class="o">=</span><span class="nx">True</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-jsx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">Output</span><span class="p">:</span>
<span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="nx">I</span> <span class="nx">enjoy</span> <span class="nx">walking</span> <span class="kd">with</span> <span class="nx">my</span> <span class="nx">cute</span> <span class="nx">dog</span><span class="p">.</span> <span class="nx">He</span> <span class="nx">will</span> <span class="nx">never</span> <span class="nx">be</span> <span class="nx">the</span> <span class="nx">same</span><span class="p">.</span> <span class="nx">I</span> <span class="nx">watch</span> <span class="nx">him</span> <span class="nx">play</span><span class="p">.</span>

<span class="nx">Guys</span><span class="p">,</span> <span class="nx">my</span> <span class="nx">dog</span> <span class="nx">needs</span> <span class="nx">a</span> <span class="nx">name</span><span class="p">.</span> <span class="nx">Especially</span> <span class="k">if</span> <span class="nx">he</span> <span class="nx">is</span> <span class="nx">found</span> <span class="kd">with</span> <span class="nx">wings</span><span class="p">.</span>

<span class="nx">What</span> <span class="nx">was</span> <span class="nx">that</span><span class="p">?</span> <span class="nx">I</span> <span class="nx">had</span> <span class="nx">a</span> <span class="nx">lot</span> <span class="nx">o</span>
</code></pre></div></div>

<p>以上结果看起来更拟人化。</p>

<p>虽然从理论上讲，Top-p似乎比Top-K更加优雅，但这两种方法在实践中都很有效。Top-p也可以与Top-K集合使用，这样可以避免排名非常低的词，同时允许进行一些动态选择。</p>

<p>最后，如果想要获得多个独立采样的输出，我们可以再次设置参数num_return_sequences &gt; 1:</p>

<div class="language-jsx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">#</span> <span class="kd">set</span> <span class="nx">seed</span> <span class="nx">to</span> <span class="nx">reproduce</span> <span class="nx">results</span><span class="p">.</span> <span class="nx">Feel</span> <span class="nx">free</span> <span class="nx">to</span> <span class="nx">change</span> <span class="nx">the</span> <span class="nx">seed</span> <span class="nx">though</span> <span class="nx">to</span> <span class="kd">get</span> <span class="nx">different</span> <span class="nx">results</span>
<span class="nx">tf</span><span class="p">.</span><span class="nx">random</span><span class="p">.</span><span class="nx">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="err">#</span> <span class="kd">set</span> <span class="nx">top_k</span> <span class="o">=</span> <span class="mi">50</span> <span class="nx">and</span> <span class="kd">set</span> <span class="nx">top_p</span> <span class="o">=</span> <span class="mf">0.95</span> <span class="nx">and</span> <span class="nx">num_return_sequences</span> <span class="o">=</span> <span class="mi">3</span>
<span class="nx">sample_outputs</span> <span class="o">=</span> <span class="nx">model</span><span class="p">.</span><span class="nx">generate</span><span class="p">(</span>
    <span class="nx">input_ids</span><span class="p">,</span>
    <span class="nx">do_sample</span><span class="o">=</span><span class="nx">True</span><span class="p">,</span>
    <span class="nx">max_length</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="nx">top_k</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="nx">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
    <span class="nx">num_return_sequences</span><span class="o">=</span><span class="mi">3</span>
<span class="p">)</span>

<span class="nx">print</span><span class="p">(</span><span class="dl">"</span><span class="s2">Output:</span><span class="se">\n</span><span class="dl">"</span> <span class="o">+</span> <span class="mi">100</span> <span class="o">*</span> <span class="dl">'</span><span class="s1">-</span><span class="dl">'</span><span class="p">)</span>
<span class="k">for</span> <span class="nx">i</span><span class="p">,</span> <span class="nx">sample_output</span> <span class="k">in</span> <span class="nx">enumerate</span><span class="p">(</span><span class="nx">sample_outputs</span><span class="p">):</span>
  <span class="nx">print</span><span class="p">(</span><span class="dl">"</span><span class="s2">{}: {}</span><span class="dl">"</span><span class="p">.</span><span class="nx">format</span><span class="p">(</span><span class="nx">i</span><span class="p">,</span> <span class="nx">tokenizer</span><span class="p">.</span><span class="nx">decode</span><span class="p">(</span><span class="nx">sample_output</span><span class="p">,</span> <span class="nx">skip_special_tokens</span><span class="o">=</span><span class="nx">True</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-jsx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">Output</span><span class="p">:</span>
<span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="mi">0</span><span class="p">:</span> <span class="nx">I</span> <span class="nx">enjoy</span> <span class="nx">walking</span> <span class="kd">with</span> <span class="nx">my</span> <span class="nx">cute</span> <span class="nx">dog</span><span class="p">.</span> <span class="nx">It</span><span class="dl">'</span><span class="s1">s so good to have the chance to walk with a dog. But I have this problem with the dog and how he</span><span class="dl">'</span><span class="nx">s</span> <span class="nx">always</span> <span class="nx">looking</span> <span class="nx">at</span> <span class="nx">us</span> <span class="nx">and</span> <span class="nx">always</span> <span class="nx">trying</span> <span class="nx">to</span> <span class="nx">make</span> <span class="nx">me</span> <span class="nx">see</span> <span class="nx">that</span> <span class="nx">I</span> <span class="nx">can</span> <span class="k">do</span> <span class="nx">something</span>
<span class="mi">1</span><span class="p">:</span> <span class="nx">I</span> <span class="nx">enjoy</span> <span class="nx">walking</span> <span class="kd">with</span> <span class="nx">my</span> <span class="nx">cute</span> <span class="nx">dog</span><span class="p">,</span> <span class="nx">she</span> <span class="nx">loves</span> <span class="nx">taking</span> <span class="nx">trips</span> <span class="nx">to</span> <span class="nx">different</span> <span class="nx">places</span> <span class="nx">on</span> <span class="nx">the</span> <span class="nx">planet</span><span class="p">,</span> <span class="nx">even</span> <span class="k">in</span> <span class="nx">the</span> <span class="nx">desert</span><span class="o">!</span> <span class="nx">The</span> <span class="nx">world</span> <span class="nx">isn</span><span class="dl">'</span><span class="s1">t big enough for us to travel by the bus with our beloved pup, but that</span><span class="dl">'</span><span class="nx">s</span> <span class="nx">where</span> <span class="nx">I</span> <span class="nx">find</span> <span class="nx">my</span> <span class="nx">love</span>
<span class="mi">2</span><span class="p">:</span> <span class="nx">I</span> <span class="nx">enjoy</span> <span class="nx">walking</span> <span class="kd">with</span> <span class="nx">my</span> <span class="nx">cute</span> <span class="nx">dog</span> <span class="nx">and</span> <span class="nx">playing</span> <span class="kd">with</span> <span class="nx">our</span> <span class="nx">kids</span><span class="p">,</span><span class="dl">"</span><span class="s2"> said David J. Smith, director of the Humane Society of the US.

</span><span class="dl">"</span><span class="nx">So</span> <span class="k">as</span> <span class="nx">a</span> <span class="nx">result</span><span class="p">,</span> <span class="nx">I</span><span class="dl">'</span><span class="s1">ve got more work in my time," he said.
</span></code></pre></div></div>

<h3 id="总结">总结</h3>

<p>在开放域语言生成场景中，作为最新的解码方法， <em>top-p</em> 和 <em>top-K</em> 采样于传统的 <em>贪心</em> 和 <em>波束</em> 搜索相比，似乎能产生更流畅的文本。但，最近有更多的证据表明 <em>贪心</em> 和 <em>波束</em> 搜索的明显缺陷 - 主要是生成重复的单词序列 - 是由模型 (特别是模型的训练方式) 引起的，而不是解码方法， <em>参见</em> <strong><a href="https://arxiv.org/pdf/1908.04319.pdf">Welleck 等人 (2019)</a></strong> 的论文。此外，如 <strong><a href="https://arxiv.org/abs/2002.02492">Welleck 等人 (2020)</a></strong> 的论文所述，看起来 <em>top-K</em> 和 <em>top-p</em> 采样也会产生重复的单词序列。</p>

<p>在 <strong><a href="https://arxiv.org/pdf/1908.04319.pdf">Welleck 等人 (2019)</a></strong> 的论文中，作者表明，根据人类评估，在调整训练目标后，波束搜索相比 <em>Top-p</em> 采样能产生更流畅的文本。</p>

<p>开放域语言生成是一个快速发展的研究领域，而且通常情况下这里没有放之四海而皆准的方法，因此必须了解哪种方法最适合自己的特定场景。</p>

<p>好的方面是， <em>你</em> 可以在 <code class="highlighter-rouge">transfomers</code> 中尝试所有不同的解码方法 🤗。</p>

<p>以上是对如何在 <code class="highlighter-rouge">transformers</code> 中使用不同的解码方法以及开放域语言生成的最新趋势的简要介绍。</p>

<h3 id="附录"><strong>附录</strong></h3>

<p><code class="highlighter-rouge">generate</code> 方法还有几个正文未提及的参数，这里我们简要解释一下它们！</p>

<ul>
  <li><code class="highlighter-rouge">min_length</code> 用于强制模型在达到 <code class="highlighter-rouge">min_length</code> 之前不生成 EOS。这在摘要场景中使用得比较多，但如果用户想要更长的文本输出，也会很有用。</li>
  <li><code class="highlighter-rouge">repetition_penalty</code> 可用于对生成重复的单词这一行为进行惩罚。它首先由 <strong><a href="https://arxiv.org/abs/1909.05858">Keskar 等人 (2019)</a></strong> 引入，在 <strong><a href="https://arxiv.org/pdf/1908.04319.pdf">Welleck 等人 (2019)</a></strong> 的工作中，它是训练目标的一部分。它可以非常有效地防止重复，但似乎对模型和用户场景非常敏感，其中一个例子见 Github 上的 <strong><a href="https://github.com/huggingface/transformers/pull/2303">讨论</a></strong>。</li>
  <li><code class="highlighter-rouge">attention_mask</code> 可用于屏蔽填充符。</li>
  <li><code class="highlighter-rouge">pad_token_id</code>、<code class="highlighter-rouge">bos_token_id</code>、<code class="highlighter-rouge">eos_token_id</code>: 如果模型默认没有这些 token，用户可以手动选择其他 token id 来表示它们。</li>
</ul>

<p>更多信息，请查阅 <code class="highlighter-rouge">generate</code> 函数 <strong><a href="https://huggingface.co/transformers/main_classes/model.html?highlight=generate#transformers.TFPreTrainedModel.generate">手册</a></strong>。</p>


                <hr style="visibility: hidden;">

                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2023/04/23/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%88%9D%E6%8E%A2-+-%E5%AE%9E%E6%96%BD%E8%B7%AF%E7%BA%BF%E6%8E%A2%E8%AE%A8/" data-toggle="tooltip" data-placement="top" title="大型语言模型初探 + 实施路线探讨">
                        Previous<br>
                        <span>大型语言模型初探 + 实施路线探讨</span>
                        </a>
                    </li>
                    
                    
                </ul>


                <!--Gitalk评论start  -->
                
                <!-- 引入Gitalk评论插件  -->
                <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
                <script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script>
                <div id="gitalk-container"></div>
                <!-- 引入一个生产md5的js，用于对id值进行处理，防止其过长 -->
                <!-- Thank DF:https://github.com/NSDingFan/NSDingFan.github.io/issues/3#issuecomment-407496538 -->
                <script src="/js/md5.min.js"></script>
                <script type="text/javascript">
                    var gitalk = new Gitalk({
                    clientID: '67895317f6288765daf1',
                    clientSecret: 'eb497ebd7d490e1fe14b52471ea090957dc55dd8',
                    repo: 'MyBlog.github.io',
                    owner: 'mengzhangjian',
                    admin: ['mengzhangjian'],
                    distractionFreeMode: true,
                    id: md5(location.pathname),
                    });
                    gitalk.render('gitalk-container');
                </script>
                
                <!-- Gitalk end -->

                

            </div>  

    <!-- Side Catalog Container -->
        
            <div class="
                col-lg-2 col-lg-offset-0
                visible-lg-block
                sidebar-container
                catalog-container">
                <div class="side-catalog">
                    <hr class="hidden-sm hidden-xs">
                    <h5>
                        <a class="catalog-toggle" href="#">CATALOG</a>
                    </h5>
                    <ul class="catalog-body"></ul>
                </div>
            </div>
        

    <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                
                <section>
                    <hr class="hidden-sm hidden-xs">
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
        				
                            
        				
                            
        				
                            
                				<a href="/tags/#DeepLearning" title="DeepLearning" rel="2">
                                    DeepLearning
                                </a>
                            
        				
                            
                				<a href="/tags/#CUDA" title="CUDA" rel="9">
                                    CUDA
                                </a>
                            
        				
                            
        				
                            
        				
                            
                				<a href="/tags/#大模型" title="大模型" rel="2">
                                    大模型
                                </a>
                            
        				
        			</div>
                </section>
                

                <!-- Friends Blog -->
                
                <hr>
                <h5>FRIENDS</h5>
                <ul class="list-inline">
                    
                        <li><a href="http://zhengwuyang.com">WY</a></li>
                    
                        <li><a href="http://www.jianshu.com/u/e71990ada2fd">简书·BY</a></li>
                    
                        <li><a href="https://apple.com">Apple</a></li>
                    
                        <li><a href="https://developer.apple.com/">Apple Developer</a></li>
                    
                </ul>
                
            </div>
        </div>
    </div>
</article>






<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/anchor-js/1.1.1/anchor.min.js",function(){
        // BY Fix:去除标题前的‘#’ issues:<https://github.com/qiubaiying/qiubaiying.github.io/issues/137>
        // anchors.options = {
        //   visible: 'always',
        //   placement: 'right',
        //   icon: '#'
        // };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>


    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    
                    <!-- add jianshu add target = "_blank" to <a> by BY -->
                    
                            <li>
                                <a target="_blank" href="https://www.jianshu.com/u/33abd4ccb0fc">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa  fa-stack-1x fa-inverse">简</i>
                                    </span>
                                </a>
                            </li>
                    
                    

                    <!-- add Weibo, Zhihu by Hux, add target = "_blank" to <a> by Hux -->
                    
                    <li>
                        <a target="_blank" href="https://www.zhihu.com/people/alphaxone">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa  fa-stack-1x fa-inverse">知</i>
                            </span>
                        </a>
                    </li>
                    
                    


                    
                    <li>
                        <a target="_blank" href="https://www.facebook.com/100006075480199">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li>
                        <a target="_blank" href="https://github.com/mengzhangjian">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; Alpha 2023
                    <br>
                    Theme on <a href="https://github.com/mengzhangjian/mengzhangjian.github.io.git">GitHub</a> |
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="100px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=mengzhangjian&repo=mengzhangjian.github.io&type=star&count=true" >
                    </iframe>
                </p>
                <p class="copyright text-muted">
                    <a href="https://beian.miit.gov.cn/" target="_blank">京ICP备2022032745号</a>
                    <a href="https://www.beian.gov.cn/portal/registerSystemInfo/" target="_blank">京公网安备11011402013706号</a>
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/hux-blog.min.js "></script>

<!-- Service Worker -->

<script type="text/javascript">
    if(navigator.serviceWorker){
        // For security reasons, a service worker can only control the pages that are in the same directory level or below it. That's why we put sw.js at ROOT level.
        navigator.serviceWorker
            .register('/sw.js')
            .then((registration) => {console.log('Service Worker Registered. ', registration)})
            .catch((error) => {console.log('ServiceWorker registration failed: ', error)})
    }
</script>



<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!-- 
     Because of the native support for backtick-style fenced code blocks 
     right within the Markdown is landed in Github Pages, 
     From V1.6, There is no need for Highlight.js, 
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0  
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/ 
     - https://github.com/jneen/rouge/wiki/list-of-supported-languages-and-lexers   
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async('/js/jquery.tagcloud.js',function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->

<script>
    // dynamic User by Hux
    var _gaId = 'UA-121837119-1';
    var _gaDomain = 'yuansearch.com';

    // Originial
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', _gaId, _gaDomain);
    ga('send', 'pageview');
</script>



<!-- Baidu Tongji -->




<!-- Side Catalog -->

<script type="text/javascript">
    function generateCatalog (selector) {
        var P = $('div.post-container'),a,n,t,l,i,c;
        a = P.find('h1,h2,h3,h4,h5,h6');
        a.each(function () {
            n = $(this).prop('tagName').toLowerCase();
            i = "#"+$(this).prop('id');
            t = $(this).text();
            c = $('<a href="'+i+'" rel="nofollow">'+t+'</a>');
            l = $('<li class="'+n+'_nav"></li>').append(c);
            $(selector).append(l);
        });
        return true;    
    }

    generateCatalog(".catalog-body");

    // toggle side catalog
    $(".catalog-toggle").click((function(e){
        e.preventDefault();
        $('.side-catalog').toggleClass("fold")
    }))

    /*
     * Doc: https://github.com/davist11/jQuery-One-Page-Nav
     * Fork by Hux to support padding
     */
    async("/js/jquery.nav.js", function () {
        $('.catalog-body').onePageNav({
            currentClass: "active",
            changeHash: !1,
            easing: "swing",
            filter: "",
            scrollSpeed: 700,
            scrollOffset: 0,
            scrollThreshold: .2,
            begin: null,
            end: null,
            scrollChange: null,
            padding: 80
        });
    });
</script>





<!-- Image to hack wechat -->
<img src="/img/apple-touch-icon.png" width="0" height="0" />
<!-- Migrate from head to bottom, no longer block render and still work -->

</body>

</html>
